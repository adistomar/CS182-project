{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = [chr(i) for i in range(ord('a'), ord('z') + 1)]\n",
    "SEP_BAR, SEP_Q = '|', '?'\n",
    "batch_size = 64\n",
    "block_size = 2048\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model checkpoint\n",
    "mono_alph_checkpoint_file = 'out/gpt2-BS-64/gpt2-BS-64_786M_ckpt.pt'\n",
    "vig_4_checkpoint_file = 'out/gpt2-vignere-scheme/gpt2-vignere-scheme_655M_ckpt.pt'\n",
    "vig_32_checkpoint_file = 'out/gpt2-vignere-scheme-key-L-32-Block3072/gpt2-vignere-scheme-key-L-32-Block3072_3932M_ckpt.pt'\n",
    "vig_rand_checkpoint_file = 'out/gpt2-vignere-scheme-key-L4thru32-Block3072-bs64/gpt2-vignere-scheme-key-L4thru32-Block3072-bs64_983M_ckpt.pt'\n",
    "checkpoint = torch.load(vig_rand_checkpoint_file, map_location=device)\n",
    "checkpoint_model_args = checkpoint['model_args']\n",
    "n_layer=12\n",
    "n_head=8\n",
    "n_embd=256\n",
    "bias=False\n",
    "dropout=0.0\n",
    "model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n",
    "                  bias=bias, vocab_size=None, dropout=dropout) # start with model_args from command line\n",
    "# force these config attributes to be equal otherwise we can't even resume training\n",
    "# the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
    "for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n",
    "    model_args[k] = checkpoint_model_args[k]\n",
    "# create the model\n",
    "gptconf = GPTConfig(**model_args)\n",
    "model = GPT(gptconf)\n",
    "state_dict = checkpoint['model']\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n",
    "state_dict = None\n",
    "iter_num = checkpoint['iter_num']\n",
    "best_val_loss = checkpoint['best_val_loss']\n",
    "total_tokens = checkpoint['total_tokens']\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'openwebtext'\n",
    "# poor man's data loader\n",
    "data_dir = os.path.join('data', dataset)\n",
    "with open(os.path.join(data_dir, 'meta.pkl'), 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta['stoi'], meta['itos']\n",
    "vocab_size = meta['vocab_size'] \n",
    "print(f\"Using vocab size of {vocab_size} (a-z + separators)\")\n",
    "\n",
    "# ---------------- helper: random mono‑alphabetic key --------\n",
    "alpha_ids = np.array([stoi[c] for c in ALPHABET], dtype=np.uint8)\n",
    "def random_key():\n",
    "    perm = np.random.permutation(26)\n",
    "    enc  = {alpha_ids[i]: alpha_ids[perm[i]] for i in range(26)}   # plain→cipher\n",
    "    dec  = {v: k for k, v in enc.items()}                          # cipher→plain\n",
    "    return enc, dec\n",
    "\n",
    "def get_batch(split):\n",
    "    mmap = np.memmap(os.path.join(data_dir, f'{split}.bin'),\n",
    "                     dtype=np.uint8, mode='r')\n",
    "\n",
    "    k_pairs   = 1024                              # desired number of pairs\n",
    "    known_k   = k_pairs - 1                       # last one is the query\n",
    "    prompt_sz = 2 * k_pairs                       # 2048 tokens\n",
    "    assert prompt_sz == block_size, \"block_size must be 2*k_pairs\"\n",
    "\n",
    "    X = torch.full((batch_size, block_size - 1), stoi['|'],  dtype=torch.long)\n",
    "    Y = torch.full((batch_size, block_size - 1), -1,          dtype=torch.long)\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # ----- 1. grab k plaintext letters from corpus -------------------\n",
    "        start = np.random.randint(0, len(mmap) - k_pairs - 1)\n",
    "        plain = mmap[start:start + k_pairs].copy()          # np.uint8, shape (k_pairs,)\n",
    "\n",
    "        # ----- 2. fresh random key for this sample -----------------------\n",
    "        enc, _ = random_key()\n",
    "\n",
    "        # ----- 3. build prompt ------------------------------------------\n",
    "        buf, tgt = [], []\n",
    "        for i, p in enumerate(plain):\n",
    "            c = enc[p]\n",
    "            if i < known_k:                                 # give answer\n",
    "                buf.extend([c, p])\n",
    "                tgt.extend([p, -1])\n",
    "            else:                                           # query pair\n",
    "                buf.extend([c])\n",
    "                tgt.extend([p])\n",
    "\n",
    "        X[b] = torch.from_numpy(np.asarray(buf,  np.uint8))\n",
    "        Y[b] = torch.from_numpy(np.asarray(tgt, np.int64))\n",
    "\n",
    "    if device_type == 'cuda':\n",
    "        X, Y = X.pin_memory().to(device, non_blocking=True), \\\n",
    "               Y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "    return X, Y\n",
    "\n",
    "eval_iters = 50\n",
    "dtype = 'bfloat16'\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "model.to(device)\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            X.to(device)\n",
    "            Y.to(device)\n",
    "            with ctx:\n",
    "                logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = estimate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l['train'], l['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def visualize_samples(num_samples=5, split='val'):\n",
    "    \"\"\"\n",
    "    Visualize samples from the dataset, showing the overall distribution of plaintext characters.\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of samples to process\n",
    "        split: Dataset split to use ('train' or 'val')\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # For tracking the distribution of plaintext characters after query ciphertext\n",
    "    query_cipher_to_plain = {}\n",
    "    \n",
    "    # For tracking model predictions vs true labels\n",
    "    true_vs_pred = {}\n",
    "    \n",
    "    # Process samples to gather distribution data\n",
    "    samples_processed = 0\n",
    "    while samples_processed < num_samples:\n",
    "        X, Y = get_batch(split)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        with ctx:\n",
    "            logits, _ = model(X, Y)\n",
    "        \n",
    "        # For each batch item\n",
    "        for i in range(X.shape[0]):\n",
    "            # Find the last position in the sequence (where the model makes its prediction)\n",
    "            seq_len = (X[i] != 0).sum().item()  # Count non-padding tokens\n",
    "            if seq_len == 0:\n",
    "                continue\n",
    "                \n",
    "            # The last position is where the prediction happens\n",
    "            pred_pos = seq_len - 1\n",
    "            \n",
    "            # Get the true label\n",
    "            true_label = Y[i, pred_pos].item()\n",
    "            \n",
    "            # Skip if true_label is -1 (padding)\n",
    "            if true_label == -1:\n",
    "                continue\n",
    "            \n",
    "            # Get model's prediction\n",
    "            pred_label = logits[i, pred_pos].argmax(dim=-1).item()\n",
    "            \n",
    "            # Track true vs predicted\n",
    "            true_char = itos[true_label]\n",
    "            pred_char = itos[pred_label]\n",
    "            \n",
    "            if true_char not in true_vs_pred:\n",
    "                true_vs_pred[true_char] = {}\n",
    "            \n",
    "            if pred_char not in true_vs_pred[true_char]:\n",
    "                true_vs_pred[true_char][pred_char] = 0\n",
    "                \n",
    "            true_vs_pred[true_char][pred_char] += 1\n",
    "            \n",
    "            # Track the distribution of plaintext characters after query ciphertext\n",
    "            # The last character in the sequence is the ciphertext we're querying about\n",
    "            cipher_char = itos[X[i, pred_pos].item()]\n",
    "            plain_char = itos[true_label]\n",
    "            \n",
    "            if cipher_char not in query_cipher_to_plain:\n",
    "                query_cipher_to_plain[cipher_char] = {}\n",
    "            \n",
    "            if plain_char not in query_cipher_to_plain[cipher_char]:\n",
    "                query_cipher_to_plain[cipher_char][plain_char] = 0\n",
    "            \n",
    "            query_cipher_to_plain[cipher_char][plain_char] += 1\n",
    "            \n",
    "            samples_processed += 1\n",
    "            \n",
    "            # Break if we have processed enough samples\n",
    "            if samples_processed >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Calculate the overall distribution of plaintext characters\n",
    "    all_plain_counts = {}\n",
    "    for cipher_dict in query_cipher_to_plain.values():\n",
    "        for plain, count in cipher_dict.items():\n",
    "            if plain not in all_plain_counts:\n",
    "                all_plain_counts[plain] = 0\n",
    "            all_plain_counts[plain] += count\n",
    "    \n",
    "    # Calculate total count for percentage calculation\n",
    "    total_count = sum(all_plain_counts.values())\n",
    "    \n",
    "    # Calculate percentages\n",
    "    all_plain_percentages = {plain: (count / total_count) * 100 for plain, count in all_plain_counts.items()}\n",
    "    \n",
    "    # First visualization: Overall distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sorted_plains = sorted(all_plain_counts.keys())\n",
    "    bars = plt.bar(sorted_plains, [all_plain_percentages[p] for p in sorted_plains])\n",
    "    plt.title(f'Distribution of Final Plaintext Characters in Dataset (Total: {total_count} characters)', fontsize=18)\n",
    "    plt.xlabel('Plaintext Character', fontsize=16)\n",
    "    plt.ylabel('Percentage (%)', fontsize=16)\n",
    "    plt.xticks(rotation=0, fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # Set a higher y-axis limit to make room for percentage labels\n",
    "    max_percentage = max(all_plain_percentages.values())\n",
    "    plt.ylim(0, max_percentage * 1.2)  # Add 20% more space above the highest bar\n",
    "    \n",
    "    # Add percentage labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Second visualization: Model predictions vs true labels\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Get all unique characters\n",
    "    all_chars = sorted(set(list(true_vs_pred.keys()) + \n",
    "                          [pred for true_dict in true_vs_pred.values() for pred in true_dict.keys()]))\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    confusion = np.zeros((len(all_chars), len(all_chars)))\n",
    "    char_to_idx = {char: i for i, char in enumerate(all_chars)}\n",
    "    \n",
    "    for true_char, pred_dict in true_vs_pred.items():\n",
    "        true_idx = char_to_idx[true_char]\n",
    "        for pred_char, count in pred_dict.items():\n",
    "            pred_idx = char_to_idx[pred_char]\n",
    "            confusion[true_idx, pred_idx] = count\n",
    "    \n",
    "    # Normalize by row (true labels)\n",
    "    row_sums = confusion.sum(axis=1, keepdims=True)\n",
    "    confusion_norm = np.zeros_like(confusion)\n",
    "    np.divide(confusion, row_sums, out=confusion_norm, where=row_sums!=0)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.imshow(confusion_norm, cmap='Blues')\n",
    "    cbar = plt.colorbar(label='Prediction Frequency')\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    cbar.set_label('Prediction Frequency', fontsize=16)\n",
    "    plt.title('Model Predictions vs True Plaintext Characters', fontsize=18)\n",
    "    plt.xlabel('Predicted Plaintext Character', fontsize=16)\n",
    "    plt.ylabel('True Plaintext Character', fontsize=16)\n",
    "    \n",
    "    # Set ticks\n",
    "    plt.xticks(np.arange(len(all_chars)), all_chars, fontsize=14)\n",
    "    plt.yticks(np.arange(len(all_chars)), all_chars, fontsize=14)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(len(all_chars)):\n",
    "        for j in range(len(all_chars)):\n",
    "            if confusion_norm[i, j] > 0:\n",
    "                text_color = 'white' if confusion_norm[i, j] > 0.5 else 'black'\n",
    "                plt.text(j, i, f'{confusion_norm[i, j]:.2f}', \n",
    "                        ha='center', va='center', color=text_color,\n",
    "                        fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the overall distribution from the validation set\n",
    "visualize_samples(num_samples=10000, split='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Example data — replace with your actual values\n",
    "learning_rates = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 3e0, 1e1]\n",
    "validation_scores = [1.7007, 0.3562, 0.0850, 0.0075, 0.0030, 0.0033, 0.2328, 0.3596]\n",
    "\n",
    "# Prepare heatmap data: 1 row, many columns\n",
    "data = np.array([validation_scores])\n",
    "\n",
    "# Convert LR to string for display\n",
    "lr_labels = [f\"{lr:.0e}\" for lr in learning_rates]\n",
    "\n",
    "# Set up the plot with wider figure\n",
    "plt.figure(figsize=(16, 3))\n",
    "ax = sns.heatmap(\n",
    "    data,\n",
    "    annot=True,\n",
    "    fmt=\".4f\",\n",
    "    cmap=\"viridis\",\n",
    "    xticklabels=False,  # Disable default x-tick labels\n",
    "    yticklabels=[\"Val Loss\"],\n",
    "    cbar_kws={\"label\": \"Validation Loss\"},\n",
    "    annot_kws={\"fontsize\": 18, \"fontfamily\": \"monospace\"}\n",
    ")\n",
    "\n",
    "# Manually set centered x-tick labels\n",
    "ax.set_xticks(np.arange(len(lr_labels)) + 0.5)  # Centered ticks\n",
    "ax.set_xticklabels(lr_labels, fontsize=18, rotation=0)\n",
    "\n",
    "# Label and title with larger font sizes\n",
    "ax.set_xlabel(\"Learning Rate\", fontsize=20)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=18)\n",
    "\n",
    "# Increase font size of colorbar\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=18)\n",
    "cbar.set_label(\"Val Loss\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def extract_learning_rate(log_file_path):\n",
    "    # Extract learning rate from filename (e.g., 'lr-1e-3.log' -> '1e-3')\n",
    "    match = re.search(r'lr-([0-9e\\-]+)', log_file_path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"unknown\"\n",
    "\n",
    "def parse_log_file(log_file_path):\n",
    "    with open(log_file_path, 'r') as f:\n",
    "        log_data = f.read()\n",
    "    \n",
    "    # Extract learning rate from filename\n",
    "    lr = extract_learning_rate(log_file_path)\n",
    "    \n",
    "    # Pattern to extract training loss from \"iter X: loss Y\"\n",
    "    train_loss_pattern = re.compile(r\"iter (\\d+): loss ([\\d.]+)\")\n",
    "    train_iters = []\n",
    "    train_losses = []\n",
    "\n",
    "    for match in train_loss_pattern.findall(log_data):\n",
    "        iter_num = int(match[0])\n",
    "        loss_val = float(match[1])\n",
    "        train_iters.append(iter_num * 256)\n",
    "        train_losses.append(loss_val)\n",
    "\n",
    "    # Pattern to extract validation loss from \"step X: train loss A, val loss B\"\n",
    "    val_loss_pattern = re.compile(r\"step (\\d+): train loss [\\d.]+, val loss ([\\d.]+)\")\n",
    "    val_steps = []\n",
    "    val_losses = []\n",
    "\n",
    "    for match in val_loss_pattern.findall(log_data):\n",
    "        step_num = int(match[0])\n",
    "        val_loss_val = float(match[1])\n",
    "        val_steps.append(step_num * 256)\n",
    "        val_losses.append(val_loss_val)\n",
    "    \n",
    "    return {\n",
    "        'lr': lr,\n",
    "        'train_iters': train_iters,\n",
    "        'train_losses': train_losses,\n",
    "        'val_steps': val_steps,\n",
    "        'val_losses': val_losses\n",
    "    }\n",
    "\n",
    "def thousands_formatter(x, pos):\n",
    "    if x >= 1000:\n",
    "        return f'{x/1000:.0f}k'\n",
    "    return f'{x:.0f}'\n",
    "\n",
    "def plot_loss_curves(*log_file_paths):\n",
    "    # Parse all log files\n",
    "    all_data = [parse_log_file(path) for path in log_file_paths]\n",
    "    \n",
    "    # Colors for different learning rates\n",
    "    colors = ['blue', 'red', 'green', 'purple', 'orange', 'brown', 'pink', 'gray']\n",
    "    \n",
    "    # Set larger font sizes\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 16,\n",
    "        'axes.titlesize': 20,\n",
    "        'axes.labelsize': 18,\n",
    "        'xtick.labelsize': 16,\n",
    "        'ytick.labelsize': 16,\n",
    "        'legend.fontsize': 16\n",
    "    })\n",
    "    \n",
    "    # Plot training losses\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, data in enumerate(all_data):\n",
    "        color = colors[i % len(colors)]\n",
    "        plt.plot(data['train_iters'], data['train_losses'], \n",
    "                 label=f'LR={data[\"lr\"]}', color=color, linewidth=2.5)\n",
    "    \n",
    "    plt.xlabel('# Keys', fontsize=18, fontweight='bold')\n",
    "    plt.ylabel('Train Loss', fontsize=18, fontweight='bold')\n",
    "    plt.title('Training Loss Curves', fontsize=20, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=16, frameon=True, facecolor='white', edgecolor='black')\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(thousands_formatter))\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot validation losses\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, data in enumerate(all_data):\n",
    "        if data['val_steps']:  # Only plot if validation data exists\n",
    "            color = colors[i % len(colors)]\n",
    "            plt.plot(data['val_steps'], data['val_losses'], \n",
    "                     label=f'LR={data[\"lr\"]}', color=color, marker='o', markersize=10, linewidth=2.5)\n",
    "    \n",
    "    plt.xlabel('# Keys', fontsize=18, fontweight='bold')\n",
    "    plt.ylabel('Val Loss', fontsize=18, fontweight='bold')\n",
    "    plt.title('Validation Loss Curves', fontsize=20, fontweight='bold')\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=16, frameon=True, facecolor='white', edgecolor='black')\n",
    "    plt.gca().xaxis.set_major_formatter(FuncFormatter(thousands_formatter))\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves('logs/lr-1e-3-otp.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves('logs/lr-1e-3-64.log', 'logs/lr-1e-3-otp.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def model_infer(input_seq, return_all=False):\n",
    "    \"\"\"\n",
    "    Runs inference on a single input sequence and returns the model's output sequence.\n",
    "\n",
    "    Args:\n",
    "        input_seq (str): The input sequence (e.g., ciphertext or prompt).\n",
    "        return_all (bool, optional): If True, returns all predicted tokens. \n",
    "                                    If False, returns only the last token. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        If return_all=False:\n",
    "            str: The predicted output (last token).\n",
    "        If return_all=True:\n",
    "            str: The complete predicted output sequence.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Convert the input sequence to tensor\n",
    "    input_indices = torch.tensor([stoi[c] for c in input_seq], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    # Create a dummy Y for conditioning if required (same shape as input)\n",
    "    dummy_Y = torch.zeros_like(input_indices).to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    logits, _ = model(input_indices, dummy_Y)\n",
    "\n",
    "    # Take the most likely token at each position\n",
    "    predicted_indices = logits.argmax(dim=-1).squeeze(0)  # shape: (sequence length,)\n",
    "\n",
    "    if return_all:\n",
    "        # Convert back to string - full sequence\n",
    "        output_seq = ''.join([itos[idx.item()] for idx in predicted_indices])\n",
    "        return output_seq\n",
    "    else:\n",
    "        # Return only the last predicted token\n",
    "        last_token = itos[predicted_indices[-1].item()]\n",
    "        return last_token\n",
    "\n",
    "def mono_alph_naive_decrypt(input_seq, return_all=True):\n",
    "    d = {}\n",
    "    output = []\n",
    "    for i in range(len(input_seq)):\n",
    "        if i % 2 == 0: # ciphertext\n",
    "            c = input_seq[i]\n",
    "            output.append(c)\n",
    "            if c in d:\n",
    "                output.append(d[c])\n",
    "            else:\n",
    "                output.append(' ')\n",
    "        else: # plaintext\n",
    "            m = input_seq[i]\n",
    "            d[input_seq[i - 1]] = m\n",
    "    return \"\".join(output[1:])\n",
    "\n",
    "def mono_alph_freq_decrypt(input_seq, return_all=True):\n",
    "    d = {}\n",
    "    output = []\n",
    "    known_plain_chars = set()\n",
    "    freq_order = \"etaoinshrdlcumwfgypbvkjxqz\"\n",
    "    freq_idx = 0\n",
    "    for i in range(len(input_seq)):\n",
    "        if i % 2 == 0: # ciphertext\n",
    "            c = input_seq[i]\n",
    "            output.append(c)\n",
    "            if c in d:\n",
    "                output.append(d[c])\n",
    "            else:\n",
    "                while freq_order[freq_idx] in known_plain_chars:\n",
    "                    freq_idx += 1\n",
    "                output.append(freq_order[freq_idx])\n",
    "        else: # plaintext\n",
    "            m = input_seq[i]\n",
    "            d[input_seq[i - 1]] = m\n",
    "            known_plain_chars.add(m)\n",
    "    return \"\".join(output[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ids = np.array([stoi[c] for c in ALPHABET], dtype=np.uint8)\n",
    "class EncryptionScheme():\n",
    "    def enc(self, plain):\n",
    "        raise NotImplementedError(\"Must be implemented in subclass\")\n",
    "    \n",
    "    def dec(self, cipher):\n",
    "        raise NotImplementedError(\"Must be implemented in subclass\")\n",
    "\n",
    "class MonoAlphabetic(EncryptionScheme):\n",
    "    def __init__(self):\n",
    "        self.perm = np.random.permutation(26)\n",
    "        self.enc_map  = {alpha_ids[i]: alpha_ids[self.perm[i]] for i in range(26)}   # plain→cipher\n",
    "        self.dec_map  = {v: k for k, v in self.enc_map.items()}                          # cipher→plain\n",
    "\n",
    "    def enc(self, plain):\n",
    "        return self.enc_map[plain]\n",
    "\n",
    "    def dec(self, cipher):\n",
    "        return self.dec_map[cipher]\n",
    "\n",
    "class Vigenere(EncryptionScheme):\n",
    "    def __init__(self, key_length):\n",
    "        self.key_length = key_length\n",
    "        self.key = np.random.choice(alpha_ids, size=key_length, replace=True)\n",
    "        self.enc_idx = 0\n",
    "        self.dec_idx = 0\n",
    "\n",
    "    def enc(self, plain):\n",
    "        shift = self.key[self.enc_idx % self.key_length]\n",
    "        c = (plain + shift) % len(alpha_ids) \n",
    "        self.enc_idx += 1\n",
    "        return c\n",
    "\n",
    "    def dec(self, cipher):\n",
    "        shift = self.key[self.dec_idx % self.key_length]\n",
    "        p = (cipher - shift) % len(alpha_ids)\n",
    "        self.dec_idx += 1\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a random sentence from the validation set\n",
    "data_dir = os.path.join('data', dataset)\n",
    "val_mmap = np.memmap(os.path.join(data_dir, 'val.bin'), dtype=np.uint8, mode='r')\n",
    "\n",
    "# Get a random segment of text (let's say 30 characters)\n",
    "sample_length = 100\n",
    "start_idx = np.random.randint(0, len(val_mmap) - sample_length)\n",
    "plain_ids = val_mmap[start_idx:start_idx + sample_length].copy()\n",
    "\n",
    "# Convert to plaintext\n",
    "plain = ''.join([itos[idx] for idx in plain_ids])\n",
    "print(f\"Plaintext: {plain}\")\n",
    "\n",
    "# Generate a random encryption key\n",
    "scheme = MonoAlphabetic()\n",
    "enc, dec = scheme.enc, scheme.dec\n",
    "\n",
    "# Encrypt the plaintext\n",
    "cipher_ids = np.array([enc(p) for p in plain_ids], dtype=np.uint8)\n",
    "cipher = ''.join([itos[idx] for idx in cipher_ids])\n",
    "print(f\"Ciphertext: {cipher}\")\n",
    "\n",
    "# Create the prompt for the model (all but last character pairs)\n",
    "known_k = len(plain_ids) - 1\n",
    "buf = []\n",
    "for i in range(known_k):\n",
    "    buf.extend([cipher_ids[i], plain_ids[i]])\n",
    "buf.append(cipher_ids[known_k])  # Add the last cipher character as query\n",
    "\n",
    "# Convert to string for visualization\n",
    "prompt_str = ''.join([itos[idx] for idx in buf])\n",
    "print(f\"Model prompt: {prompt_str}\")\n",
    "\n",
    "# Prepare input for model_infer\n",
    "input_seq = prompt_str\n",
    "\n",
    "# Get the ground truth (the last plaintext character)\n",
    "ground_truth = itos[plain_ids[known_k]]\n",
    "print(f\"Ground truth (last character): {ground_truth}\")\n",
    "\n",
    "# The model will predict this in the next cell\n",
    "print(f\"The model will predict the decryption of '{itos[cipher_ids[known_k]]}' → ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_infer(input_seq, return_all=True)\n",
    "output1 = mono_alph_naive_decrypt(input_seq, return_all = True)\n",
    "print(\"out seq:\", output[0:-1:2] + output[-1]) \n",
    "print(\"tru seq:\", plain)\n",
    "print(f\"decrypting {itos[cipher_ids[known_k]]} →\", output[-1])\n",
    "\n",
    "print('---------------------------')\n",
    "print(\"out seq:\", output1[0:-1:2] + output1[-1]) \n",
    "print(\"tru seq:\", plain)\n",
    "print(f\"decrypting {itos[cipher_ids[known_k]]} →\", output1[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "def evaluate_in_context_learning(model_fn, scheme_name='mono', vig_key_size=None, num_samples=1000, max_examples=1023, uniform_sampling=False):\n",
    "    position_correct = {}\n",
    "    position_total = {}\n",
    "\n",
    "    for _ in tqdm(range(num_samples), desc=f\"Evaluating ({model_fn.__name__})\"):\n",
    "        sample_length = max_examples + 1\n",
    "        if uniform_sampling:\n",
    "            plain_ids = np.random.randint(0, len(alpha_ids), size=sample_length, dtype=np.uint8)\n",
    "        else:\n",
    "            start_idx = np.random.randint(0, len(val_mmap) - sample_length)\n",
    "            plain_ids = val_mmap[start_idx:start_idx + sample_length].copy()\n",
    "        \n",
    "        if scheme_name == 'mono':\n",
    "            scheme = MonoAlphabetic()\n",
    "        elif scheme_name == 'vigenere':\n",
    "            if vig_key_size is None:\n",
    "                raise ValueError(\"poly_key_size must be specified for poly-alphabetic schemes\")   \n",
    "            if vig_key_size == 'random':\n",
    "                scheme = Vigenere(np.random.randint(4, 32))\n",
    "            else:\n",
    "                scheme = Vigenere(vig_key_size)\n",
    "        enc, dec = scheme.enc, scheme.dec\n",
    "        cipher_ids = np.array([enc(p) for p in plain_ids], dtype=np.uint8)\n",
    "\n",
    "        buf = []\n",
    "        for i in range(max_examples):\n",
    "            buf.extend([cipher_ids[i], plain_ids[i]])\n",
    "        buf.append(cipher_ids[max_examples])\n",
    "\n",
    "        prompt_str = ''.join([itos[idx] for idx in buf])\n",
    "        output = model_fn(prompt_str, return_all=True)\n",
    "\n",
    "        for i in range(max_examples):\n",
    "            position = i + 1\n",
    "            pred_idx = 2 * i\n",
    "            ground_truth = itos[plain_ids[i]]\n",
    "            pred_char = output[pred_idx]\n",
    "\n",
    "            if position not in position_correct:\n",
    "                position_correct[position] = 0\n",
    "                position_total[position] = 0\n",
    "\n",
    "            if pred_char == ground_truth:\n",
    "                position_correct[position] += 1\n",
    "            position_total[position] += 1\n",
    "\n",
    "    positions = sorted(position_total.keys())\n",
    "    accuracies = [position_correct[pos] / position_total[pos] for pos in positions]\n",
    "    return positions, accuracies\n",
    "\n",
    "def plot_accuracy_comparison(positions, *model_results, max_position=None):\n",
    "    # Apply cutoff if max_position is set\n",
    "    if max_position is not None:\n",
    "        positions = [p for p in positions if p <= max_position]\n",
    "        model_results = [\n",
    "            (name, acc[:len(positions)])\n",
    "            for name, acc in model_results\n",
    "        ]\n",
    "\n",
    "    for scale in ['log', 'linear']:\n",
    "        plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "        for name, accuracies in model_results:\n",
    "            plt.plot(positions, accuracies, label=name, linewidth=2.5, alpha=0.85)\n",
    "\n",
    "        if scale == 'log':\n",
    "            plt.xscale('log')\n",
    "            xtick_vals = [p for p in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1023, 1535] if p <= positions[-1]]\n",
    "            plt.xticks(xtick_vals, [str(p) for p in xtick_vals], rotation=45)\n",
    "\n",
    "        plt.xlabel('Number of In-Context Examples Seen', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "        plt.title(f'Model Accuracy vs. Number of In-Context Examples ({scale.capitalize()} Scale)',\n",
    "                  fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "        plt.grid(True, which=\"both\", ls=\"--\", alpha=0.3)\n",
    "        plt.legend(fontsize=11)\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.set_facecolor('#f8f9fa')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(True)\n",
    "            spine.set_color('#cccccc')\n",
    "            spine.set_linewidth(0.8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mono-Alphabetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Distribution (OpenWebText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_train_transformer, acc_mono_train_transformer = evaluate_in_context_learning(model_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_train_naive, acc_mono_train_naive = evaluate_in_context_learning(mono_alph_naive_decrypt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_train_freq, acc_mono_train_freq = evaluate_in_context_learning(mono_alph_freq_decrypt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_mono_train_transformer,\n",
    "    (\"Transformer\", acc_mono_train_transformer),\n",
    "    (\"Naive Attack\", acc_mono_train_naive),\n",
    "    (\"Frequency Based Attack\", acc_mono_train_freq),\n",
    "    max_position=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_uniform_transformer, acc_mono_uniform_transformer = evaluate_in_context_learning(model_infer, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_uniform_naive, acc_mono_uniform_naive = evaluate_in_context_learning(mono_alph_naive_decrypt, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_mono_uniform_freq, acc_mono_uniform_freq = evaluate_in_context_learning(mono_alph_freq_decrypt, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_mono_uniform_transformer,\n",
    "    (\"Transformer\", acc_mono_uniform_transformer),\n",
    "    (\"Naive Attack\", acc_mono_uniform_naive),\n",
    "    (\"Frequency Based Attack\", acc_mono_uniform_freq),\n",
    "    max_position=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vigenere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch2i(ch: str):\n",
    "    return ord(ch) - 97 \n",
    "    \n",
    "def i2ch(i: int):        \n",
    "    return chr((i % 26) + 97)\n",
    "\n",
    "def vigenere_naive_decrypt(key_len):\n",
    "\n",
    "    def func(input_seq, return_all=True):\n",
    "        \n",
    "        key_table = [None] * key_len    \n",
    "        output    = []\n",
    "        \n",
    "        for i, ch in enumerate(input_seq):\n",
    "            if i % 2 == 0:                       \n",
    "                c = ch\n",
    "                output.append(c)                \n",
    "                \n",
    "                pos = i // 2              \n",
    "                key_idx = pos % key_len\n",
    "                key_offset = key_table[key_idx]\n",
    "                \n",
    "                if key_offset is not None:      \n",
    "                    p = i2ch((ch2i(c) - key_offset) % 26)\n",
    "                else:                            \n",
    "                    p = ' '\n",
    "                output.append(p)\n",
    "            \n",
    "            else:                               \n",
    "                p = ch\n",
    "                c = input_seq[i - 1]\n",
    "                pos     = (i - 1) // 2\n",
    "                key_idx = pos % key_len\n",
    "                key_table[key_idx] = (ch2i(c) - ch2i(p)) % 26 \n",
    "        \n",
    "        decoded_seq = \"\".join(output[1:])        \n",
    "        \n",
    "        return decoded_seq if return_all else (decoded_seq[-1] if decoded_seq else \"\")\n",
    "        \n",
    "    return func\n",
    "\n",
    "def vigenere_freq_decrypt(key_len):\n",
    "\n",
    "    def func(input_seq, return_all=True):\n",
    "        \n",
    "        key_table = [None] * key_len    \n",
    "        output    = []\n",
    "        \n",
    "        for i, ch in enumerate(input_seq):\n",
    "            if i % 2 == 0:                       \n",
    "                c = ch\n",
    "                output.append(c)                \n",
    "                \n",
    "                pos = i // 2              \n",
    "                key_idx = pos % key_len\n",
    "                key_offset = key_table[key_idx]\n",
    "                \n",
    "                if key_offset is not None:      \n",
    "                    p = i2ch((ch2i(c) - key_offset) % 26)\n",
    "                else:                            \n",
    "                    p = 'e'\n",
    "                output.append(p)\n",
    "            \n",
    "            else:                               \n",
    "                p = ch\n",
    "                c = input_seq[i - 1]\n",
    "                pos     = (i - 1) // 2\n",
    "                key_idx = pos % key_len\n",
    "                key_table[key_idx] = (ch2i(c) - ch2i(p)) % 26 \n",
    "        \n",
    "        decoded_seq = \"\".join(output[1:])        \n",
    "        \n",
    "        return decoded_seq if return_all else (decoded_seq[-1] if decoded_seq else \"\")\n",
    "        \n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Size: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_naive, acc_vig_train_naive = evaluate_in_context_learning(vigenere_naive_decrypt(4), scheme_name='vigenere', vig_key_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq, acc_vig_train_freq = evaluate_in_context_learning(vigenere_freq_decrypt(4), scheme_name='vigenere', vig_key_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Naive Attack\", acc_vig_train_naive),\n",
    "    (\"Frequency Based Attack\", acc_vig_train_freq),\n",
    "    max_position=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_transformer, acc_vig_uniform_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=4, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_naive, acc_vig_uniform_naive = evaluate_in_context_learning(vigenere_naive_decrypt(4), scheme_name='vigenere', vig_key_size=4, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_freq, acc_vig_uniform_freq = evaluate_in_context_learning(vigenere_freq_decrypt(4), scheme_name='vigenere', vig_key_size=4, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_uniform_transformer),\n",
    "    (\"Naive Attack\", acc_vig_uniform_naive),\n",
    "    (\"Frequency Based Attack\", acc_vig_uniform_freq),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Size: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_naive, acc_vig_train_naive = evaluate_in_context_learning(vigenere_naive_decrypt(32), scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq, acc_vig_train_freq = evaluate_in_context_learning(vigenere_freq_decrypt(32), scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Naive Attack\", acc_vig_train_naive),\n",
    "    (\"Frequency Based Attack\", acc_vig_train_freq),\n",
    "    max_position=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_transformer, acc_vig_uniform_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=32, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_naive, acc_vig_uniform_naive = evaluate_in_context_learning(vigenere_naive_decrypt(32), scheme_name='vigenere', vig_key_size=32, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_freq, acc_vig_uniform_freq = evaluate_in_context_learning(vigenere_freq_decrypt(32), scheme_name='vigenere', vig_key_size=32, uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_uniform_transformer),\n",
    "    (\"Naive Attack\", acc_vig_uniform_naive),\n",
    "    (\"Frequency Based Attack\", acc_vig_uniform_freq),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Distribution, Key Len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq_32, acc_vig_train_freq_32 = evaluate_in_context_learning(vigenere_freq_decrypt(32), scheme_name='vigenere', vig_key_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq_16, acc_vig_train_freq_16 = evaluate_in_context_learning(vigenere_freq_decrypt(16), scheme_name='vigenere', vig_key_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Frequency Based Attack on Key Length 32\", acc_vig_train_freq_32),\n",
    "    (\"Frequency Based Attack on Key Length 16\", acc_vig_train_freq_16),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Distribution, Key Len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, scheme_name='vigenere', vig_key_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq_32, acc_vig_train_freq_32 = evaluate_in_context_learning(vigenere_freq_decrypt(32), scheme_name='vigenere', vig_key_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq_20, acc_vig_train_freq_20 = evaluate_in_context_learning(vigenere_freq_decrypt(20), scheme_name='vigenere', vig_key_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Frequency Based Attack on Key Length 32\", acc_vig_train_freq_32),\n",
    "    (\"Frequency Based Attack on Key Length 20\", acc_vig_train_freq_20),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Length: Random (4 - 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vigenere_unknownlen_naive(input_seq: str, return_all: bool = True):\n",
    "    min_len = 4\n",
    "    max_len = 32\n",
    "    candidates = [\n",
    "        {\"len\": L, \"table\": [None] * L, \"valid\": True} for L in range(min_len, max_len + 1)\n",
    "    ]\n",
    "    output = []\n",
    "\n",
    "    for i, ch in enumerate(input_seq):\n",
    "        if i % 2 == 0:\n",
    "            c = ch\n",
    "            output.append(c)\n",
    "\n",
    "            pos = i // 2\n",
    "            shifts = []\n",
    "            for cand in candidates:\n",
    "                if not cand[\"valid\"]:\n",
    "                    continue\n",
    "                shift = cand[\"table\"][pos % cand[\"len\"]]\n",
    "                shifts.append(shift)\n",
    "\n",
    "            known = [s for s in shifts if s is not None]\n",
    "            if known and all(s == known[0] for s in known):\n",
    "                p = i2ch((ch2i(c) - known[0]) % 26)\n",
    "            else:\n",
    "                p = \" \"          \n",
    "            output.append(p)\n",
    "\n",
    "        else:\n",
    "            p = ch\n",
    "            c = input_seq[i - 1]\n",
    "            pos = (i - 1) // 2\n",
    "            want = (ch2i(c) - ch2i(p)) % 26\n",
    "\n",
    "            for cand in candidates:\n",
    "                if not cand[\"valid\"]:\n",
    "                    continue\n",
    "                kidx = pos % cand[\"len\"]\n",
    "                known = cand[\"table\"][kidx]\n",
    "                if known is None:\n",
    "                    cand[\"table\"][kidx] = want\n",
    "                elif known != want:\n",
    "                    cand[\"valid\"] = False  \n",
    "\n",
    "    decoded = \"\".join(output[1:])  \n",
    "    return decoded if return_all else (decoded[-1] if decoded else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, max_examples=1535, scheme_name='vigenere', vig_key_size='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_naive, acc_vig_train_naive = evaluate_in_context_learning(vigenere_unknownlen_naive, max_examples=1535, scheme_name='vigenere', vig_key_size='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_train_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Naive Attack\", acc_vig_train_naive),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_transformer, acc_vig_uniform_transformer = evaluate_in_context_learning(model_infer, max_examples=1535, scheme_name='vigenere', vig_key_size='random', uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_uniform_naive, acc_vig_uniform_naive = evaluate_in_context_learning(vigenere_unknownlen_naive, max_examples=1535, scheme_name='vigenere', vig_key_size='random', uniform_sampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_uniform_transformer,\n",
    "    (\"Transformer\", acc_vig_uniform_transformer),\n",
    "    (\"Naive Attack\", acc_vig_uniform_naive),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Distribution, Key Len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_transformer, acc_vig_train_transformer = evaluate_in_context_learning(model_infer, max_examples=1535, scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_naive, acc_vig_train_naive = evaluate_in_context_learning(vigenere_unknownlen_naive, max_examples=1535, scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_vig_train_freq_32, acc_vig_train_freq_32 = evaluate_in_context_learning(vigenere_freq_decrypt(32), max_examples=1535, scheme_name='vigenere', vig_key_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_comparison(\n",
    "    positions_vig_uniform_transformer,\n",
    "    (\"Transformer\", acc_vig_train_transformer),\n",
    "    (\"Naive Attack on Unknown Key Length\", acc_vig_train_naive),\n",
    "    (\"Frequency Based Attack on Key Length 32\", acc_vig_train_freq_32),\n",
    "    max_position=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "182env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
